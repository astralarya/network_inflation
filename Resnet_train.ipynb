{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bca5ced7",
   "metadata": {},
   "source": [
    "# Resnet Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "507a0491-3708-4d82-ae1b-f1a82b5a6069",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marakim/opt/anaconda3/envs/network_inflation/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: dlopen(/Users/marakim/opt/anaconda3/envs/network_inflation/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.8.dylib\n",
      "  Referenced from: <BE0CCD9A-269A-30E2-A23C-DA45E89EBB1F> /Users/marakim/opt/anaconda3/envs/network_inflation/lib/python3.10/site-packages/torchvision/image.so\n",
      "  Reason: tried: '/Users/marakim/opt/anaconda3/envs/network_inflation/lib/python3.10/site-packages/torchvision/../../../libjpeg.8.dylib' (no such file), '/Users/marakim/opt/anaconda3/envs/network_inflation/lib/python3.10/site-packages/torchvision/../../../libjpeg.8.dylib' (no such file), '/Users/marakim/opt/anaconda3/envs/network_inflation/lib/python3.10/lib-dynload/../../libjpeg.8.dylib' (no such file), '/Users/marakim/opt/anaconda3/envs/network_inflation/bin/../lib/libjpeg.8.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS@rpath/libjpeg.8.dylib' (no such file), '/Users/marakim/opt/anaconda3/envs/network_inflation/lib/python3.10/site-packages/torchvision/../../../libjpeg.8.dylib' (no such file), '/Users/marakim/opt/anaconda3/envs/network_inflation/lib/python3.10/site-packages/torchvision/../../../libjpeg.8.dylib' (no such file), '/Users/marakim/opt/anaconda3/envs/network_inflation/lib/python3.10/lib-dynload/../../libjpeg.8.dylib' (no such file), '/Users/marakim/opt/anaconda3/envs/network_inflation/bin/../lib/libjpeg.8.dylib' (no such file), '/usr/local/lib/libjpeg.8.dylib' (no such file), '/usr/lib/libjpeg.8.dylib' (no such file, not in dyld cache)\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n",
      "Using cache found in /Users/marakim/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "Using cache found in /Users/marakim/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "Using cache found in /Users/marakim/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "Using cache found in /Users/marakim/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "Using cache found in /Users/marakim/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.13.1\n",
      "Torchvision Version:  0.14.1a0\n",
      "Pytorch device:  mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchinfo import summary\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from local import model\n",
    "from local import imagenet\n",
    "from local import resnet\n",
    "from local.device import device, cpu\n",
    "\n",
    "\n",
    "print(\"PyTorch Version: \", torch.__version__)\n",
    "print(\"Torchvision Version: \", torchvision.__version__)\n",
    "print(\"Pytorch device: \", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7104c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_data = torchvision.datasets.ImageNet('~/Documents/research/imagenet/', split=\"train\", transform=preprocess)\n",
    "data_root = '~/Documents/research/imagenet/ILSVRC/Data/CLS-LOC/train/'\n",
    "\n",
    "train_data = imagenet.train_data(data_root)\n",
    "eval_data = imagenet.eval_data(data_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "624ca1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18 = model.clone(resnet.resnet18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19537089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0104, -0.0061, -0.0018,  0.0748,  0.0566,  0.0171, -0.0127],\n",
       "        [ 0.0111,  0.0095, -0.1099, -0.2805, -0.2712, -0.1291,  0.0037],\n",
       "        [-0.0069,  0.0591,  0.2955,  0.5872,  0.5197,  0.2563,  0.0636],\n",
       "        [ 0.0305, -0.0670, -0.2984, -0.4387, -0.2709, -0.0006,  0.0576],\n",
       "        [-0.0275,  0.0160,  0.0726, -0.0541, -0.3328, -0.4206, -0.2578],\n",
       "        [ 0.0306,  0.0410,  0.0628,  0.2390,  0.4138,  0.3936,  0.1661],\n",
       "        [-0.0137, -0.0037, -0.0241, -0.0659, -0.1507, -0.0822, -0.0058]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet18.get_parameter('conv1.weight')[0,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76948564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading `models/resnet18.00000001.pkl`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load(resnet18, \"resnet18\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a028d991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0146, -0.0094, -0.0036,  0.0737,  0.0556,  0.0149, -0.0140],\n",
       "        [ 0.0066,  0.0057, -0.1118, -0.2823, -0.2723, -0.1313,  0.0019],\n",
       "        [-0.0115,  0.0554,  0.2937,  0.5855,  0.5185,  0.2549,  0.0619],\n",
       "        [ 0.0264, -0.0711, -0.3002, -0.4397, -0.2714, -0.0013,  0.0557],\n",
       "        [-0.0311,  0.0128,  0.0708, -0.0548, -0.3332, -0.4214, -0.2594],\n",
       "        [ 0.0279,  0.0374,  0.0621,  0.2407,  0.4152,  0.3924,  0.1648],\n",
       "        [-0.0173, -0.0075, -0.0264, -0.0680, -0.1505, -0.0840, -0.0077]],\n",
       "       device='mps:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet18.get_parameter('conv1.weight')[0,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a15cd61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving `models/resnet18.00000001.pkl`\n"
     ]
    }
   ],
   "source": [
    "model.save(resnet18, \"resnet18\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a9654cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading `models/resnet18.00000001.pkl`\n",
      "Loading `None`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5005 [00:00<?, ?it/s]/Users/marakim/opt/anaconda3/envs/network_inflation/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: dlopen(/Users/marakim/opt/anaconda3/envs/network_inflation/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.8.dylib\n",
      "  Referenced from: <BE0CCD9A-269A-30E2-A23C-DA45E89EBB1F> /Users/marakim/opt/anaconda3/envs/network_inflation/lib/python3.10/site-packages/torchvision/image.so\n",
      "  Reason: tried: '/Users/marakim/opt/anaconda3/envs/network_inflation/lib/python3.10/site-packages/torchvision/../../../libjpeg.8.dylib' (no such file), '/Users/marakim/opt/anaconda3/envs/network_inflation/lib/python3.10/site-packages/torchvision/../../../libjpeg.8.dylib' (no such file), '/Users/marakim/opt/anaconda3/envs/network_inflation/lib/python3.10/lib-dynload/../../libjpeg.8.dylib' (no such file), '/Users/marakim/opt/anaconda3/envs/network_inflation/bin/../lib/libjpeg.8.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS@rpath/libjpeg.8.dylib' (no such file), '/Users/marakim/opt/anaconda3/envs/network_inflation/lib/python3.10/site-packages/torchvision/../../../libjpeg.8.dylib' (no such file), '/Users/marakim/opt/anaconda3/envs/network_inflation/lib/python3.10/site-packages/torchvision/../../../libjpeg.8.dylib' (no such file), '/Users/marakim/opt/anaconda3/envs/network_inflation/lib/python3.10/lib-dynload/../../libjpeg.8.dylib' (no such file), '/Users/marakim/opt/anaconda3/envs/network_inflation/bin/../lib/libjpeg.8.dylib' (no such file), '/usr/local/lib/libjpeg.8.dylib' (no such file), '/usr/lib/libjpeg.8.dylib' (no such file, not in dyld cache)\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n",
      "/Users/marakim/opt/anaconda3/envs/network_inflation/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: dlopen(/Users/marakim/opt/anaconda3/envs/network_inflation/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.8.dylib\n",
      "  Referenced from: <BE0CCD9A-269A-30E2-A23C-DA45E89EBB1F> /Users/marakim/opt/anaconda3/envs/network_inflation/lib/python3.10/site-packages/torchvision/image.so\n",
      "  Reason: tried: '/Users/marakim/opt/anaconda3/envs/network_inflation/lib/python3.10/site-packages/torchvision/../../../libjpeg.8.dylib' (no such file), '/Users/marakim/opt/anaconda3/envs/network_inflation/lib/python3.10/site-packages/torchvision/../../../libjpeg.8.dylib' (no such file), '/Users/marakim/opt/anaconda3/envs/network_inflation/lib/python3.10/lib-dynload/../../libjpeg.8.dylib' (no such file), '/Users/marakim/opt/anaconda3/envs/network_inflation/bin/../lib/libjpeg.8.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS@rpath/libjpeg.8.dylib' (no such file), '/Users/marakim/opt/anaconda3/envs/network_inflation/lib/python3.10/site-packages/torchvision/../../../libjpeg.8.dylib' (no such file), '/Users/marakim/opt/anaconda3/envs/network_inflation/lib/python3.10/site-packages/torchvision/../../../libjpeg.8.dylib' (no such file), '/Users/marakim/opt/anaconda3/envs/network_inflation/lib/python3.10/lib-dynload/../../libjpeg.8.dylib' (no such file), '/Users/marakim/opt/anaconda3/envs/network_inflation/bin/../lib/libjpeg.8.dylib' (no such file), '/usr/local/lib/libjpeg.8.dylib' (no such file), '/usr/lib/libjpeg.8.dylib' (no such file, not in dyld cache)\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n",
      "  1%|          | 28/5005 [00:52<2:34:28,  1.86s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m imagenet\u001b[39m.\u001b[39;49mtrain(resnet18, \u001b[39m\"\u001b[39;49m\u001b[39mresnet18\u001b[39;49m\u001b[39m\"\u001b[39;49m, train_data)\n",
      "File \u001b[0;32m~/Documents/research/network_inflation/local/imagenet.py:64\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(network, name, data, batch_size, num_epochs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     loss \u001b[39m=\u001b[39m criterion(outputs, labels\u001b[39m.\u001b[39mto(device))\n\u001b[1;32m     63\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m---> 64\u001b[0m     optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m     65\u001b[0m     epoch_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n\u001b[1;32m     66\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[epoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m]: loss: \u001b[39m\u001b[39m{\u001b[39;00mepoch_loss\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/network_inflation/lib/python3.10/site-packages/torch/optim/optimizer.py:140\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m    139\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 140\u001b[0m     out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     obj\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    142\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/network_inflation/lib/python3.10/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/network_inflation/lib/python3.10/site-packages/torch/optim/adamw.py:162\u001b[0m, in \u001b[0;36mAdamW.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    158\u001b[0m             max_exp_avg_sqs\u001b[39m.\u001b[39mappend(state[\u001b[39m'\u001b[39m\u001b[39mmax_exp_avg_sq\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m    160\u001b[0m         state_steps\u001b[39m.\u001b[39mappend(state[\u001b[39m'\u001b[39m\u001b[39mstep\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m--> 162\u001b[0m     adamw(params_with_grad,\n\u001b[1;32m    163\u001b[0m           grads,\n\u001b[1;32m    164\u001b[0m           exp_avgs,\n\u001b[1;32m    165\u001b[0m           exp_avg_sqs,\n\u001b[1;32m    166\u001b[0m           max_exp_avg_sqs,\n\u001b[1;32m    167\u001b[0m           state_steps,\n\u001b[1;32m    168\u001b[0m           amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[1;32m    169\u001b[0m           beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    170\u001b[0m           beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    171\u001b[0m           lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    172\u001b[0m           weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    173\u001b[0m           eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    174\u001b[0m           maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    175\u001b[0m           foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    176\u001b[0m           capturable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mcapturable\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m    178\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/network_inflation/lib/python3.10/site-packages/torch/optim/adamw.py:219\u001b[0m, in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    217\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_adamw\n\u001b[0;32m--> 219\u001b[0m func(params,\n\u001b[1;32m    220\u001b[0m      grads,\n\u001b[1;32m    221\u001b[0m      exp_avgs,\n\u001b[1;32m    222\u001b[0m      exp_avg_sqs,\n\u001b[1;32m    223\u001b[0m      max_exp_avg_sqs,\n\u001b[1;32m    224\u001b[0m      state_steps,\n\u001b[1;32m    225\u001b[0m      amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[1;32m    226\u001b[0m      beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    227\u001b[0m      beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    228\u001b[0m      lr\u001b[39m=\u001b[39;49mlr,\n\u001b[1;32m    229\u001b[0m      weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[1;32m    230\u001b[0m      eps\u001b[39m=\u001b[39;49meps,\n\u001b[1;32m    231\u001b[0m      maximize\u001b[39m=\u001b[39;49mmaximize,\n\u001b[1;32m    232\u001b[0m      capturable\u001b[39m=\u001b[39;49mcapturable)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/network_inflation/lib/python3.10/site-packages/torch/optim/adamw.py:318\u001b[0m, in \u001b[0;36m_single_tensor_adamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    316\u001b[0m     denom \u001b[39m=\u001b[39m (exp_avg_sq\u001b[39m.\u001b[39msqrt() \u001b[39m/\u001b[39m bias_correction2_sqrt)\u001b[39m.\u001b[39madd_(eps)\n\u001b[0;32m--> 318\u001b[0m param\u001b[39m.\u001b[39;49maddcdiv_(exp_avg, denom, value\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49mstep_size)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "imagenet.train(resnet18, \"resnet18\", train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6650e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0083, 0.0063, 0.0150],\n",
       "        [0.0184, 0.0194, 0.0168],\n",
       "        [0.0049, 0.0125, 0.0142]], grad_fn=<SelectBackward0>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resnet.resnet152.get_parameter('layer4.0.conv2.weight')[0,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53a32b07",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'AdamW' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m resnet152_finetune \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mclone(resnet\u001b[39m.\u001b[39mresnet152)\n\u001b[0;32m----> 2\u001b[0m imagenet\u001b[39m.\u001b[39;49mtrain(resnet152_finetune, \u001b[39m\"\u001b[39;49m\u001b[39mresnet152.finetune\u001b[39;49m\u001b[39m\"\u001b[39;49m, train_data)\n",
      "File \u001b[0;32m~/Documents/research/network_inflation/local/imagenet.py:47\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, name, data, batch_size, num_epochs)\u001b[0m\n\u001b[1;32m     39\u001b[0m data_loader \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataLoader2(\n\u001b[1;32m     40\u001b[0m     data,\n\u001b[1;32m     41\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m     42\u001b[0m     num_workers\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[1;32m     43\u001b[0m     shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     44\u001b[0m )\n\u001b[1;32m     46\u001b[0m criterion \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mCrossEntropyLoss()\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> 47\u001b[0m optimizer \u001b[39m=\u001b[39m optim\u001b[39m.\u001b[39;49mAdamW(model\u001b[39m.\u001b[39;49mparameters())\u001b[39m.\u001b[39;49mto(device)\n\u001b[1;32m     49\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m     51\u001b[0m model\u001b[39m.\u001b[39mto(device)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'AdamW' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "resnet152_finetune = model.clone(resnet.resnet152)\n",
    "imagenet.train(resnet152_finetune, \"resnet152.finetune\", train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9ece0ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marakim/opt/anaconda3/envs/network_inflation/lib/python3.10/site-packages/torch/_tensor_str.py:115: UserWarning: The operator 'aten::nonzero' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/miniforge3/conda-bld/pytorch-recipe_1675740407425/work/aten/src/ATen/mps/MPSFallback.mm:11.)\n",
      "  nonzero_finite_vals = torch.masked_select(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0073, 0.0053, 0.0140],\n",
       "        [0.0174, 0.0184, 0.0158],\n",
       "        [0.0039, 0.0115, 0.0132]], device='mps:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet152_finetune.get_parameter('layer4.0.conv2.weight')[0,0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "network_inflation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "a85702dbffca433bbc1cdca1ec61af2a74010ab6cab1a97332d28220958107a8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
