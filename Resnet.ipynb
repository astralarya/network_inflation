{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bca5ced7",
   "metadata": {},
   "source": [
    "# Resnet Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "507a0491-3708-4d82-ae1b-f1a82b5a6069",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marakim/opt/anaconda3/envs/network_inflation/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: dlopen(/Users/marakim/opt/anaconda3/envs/network_inflation/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.8.dylib\n",
      "  Referenced from: <BE0CCD9A-269A-30E2-A23C-DA45E89EBB1F> /Users/marakim/opt/anaconda3/envs/network_inflation/lib/python3.10/site-packages/torchvision/image.so\n",
      "  Reason: tried: '/Users/marakim/opt/anaconda3/envs/network_inflation/lib/python3.10/site-packages/torchvision/../../../libjpeg.8.dylib' (no such file), '/Users/marakim/opt/anaconda3/envs/network_inflation/lib/python3.10/site-packages/torchvision/../../../libjpeg.8.dylib' (no such file), '/Users/marakim/opt/anaconda3/envs/network_inflation/lib/python3.10/lib-dynload/../../libjpeg.8.dylib' (no such file), '/Users/marakim/opt/anaconda3/envs/network_inflation/bin/../lib/libjpeg.8.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS@rpath/libjpeg.8.dylib' (no such file), '/Users/marakim/opt/anaconda3/envs/network_inflation/lib/python3.10/site-packages/torchvision/../../../libjpeg.8.dylib' (no such file), '/Users/marakim/opt/anaconda3/envs/network_inflation/lib/python3.10/site-packages/torchvision/../../../libjpeg.8.dylib' (no such file), '/Users/marakim/opt/anaconda3/envs/network_inflation/lib/python3.10/lib-dynload/../../libjpeg.8.dylib' (no such file), '/Users/marakim/opt/anaconda3/envs/network_inflation/bin/../lib/libjpeg.8.dylib' (no such file), '/usr/local/lib/libjpeg.8.dylib' (no such file), '/usr/lib/libjpeg.8.dylib' (no such file, not in dyld cache)\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.13.1\n",
      "Torchvision Version:  0.14.1a0\n",
      "Pytorch device:  mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchinfo import summary\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = None\n",
    "\n",
    "print(\"PyTorch Version: \", torch.__version__)\n",
    "print(\"Torchvision Version: \", torchvision.__version__)\n",
    "print(\"Pytorch device: \", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f6b8e34-e589-4a49-bebe-b950e68fa0b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/marakim/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "Using cache found in /Users/marakim/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "Using cache found in /Users/marakim/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "Using cache found in /Users/marakim/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "Using cache found in /Users/marakim/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import resnet\n",
    "\n",
    "resnet18 = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', weights=resnet.ResNet18_Weights.IMAGENET1K_V1)\n",
    "resnet34 = torch.hub.load('pytorch/vision:v0.10.0', 'resnet34', weights=resnet.ResNet34_Weights.IMAGENET1K_V1)\n",
    "resnet50 = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', weights=resnet.ResNet50_Weights.IMAGENET1K_V1)\n",
    "resnet101 = torch.hub.load('pytorch/vision:v0.10.0', 'resnet101', weights=resnet.ResNet101_Weights.IMAGENET1K_V1)\n",
    "resnet152 = torch.hub.load('pytorch/vision:v0.10.0', 'resnet152', weights=resnet.ResNet152_Weights.IMAGENET1K_V1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77061032",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnets = [\n",
    "    resnet18,\n",
    "    resnet34,\n",
    "    resnet50,\n",
    "    resnet101,\n",
    "    resnet152,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7104c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_data = torchvision.datasets.ImageNet('~/Documents/research/imagenet/', split=\"train\", transform=preprocess)\n",
    "\n",
    "train_data = torchvision.datasets.ImageFolder(\n",
    "    '~/Documents/research/imagenet/ILSVRC/Data/CLS-LOC/train/',\n",
    "    transform=transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    ")\n",
    "\n",
    "eval_data = torchvision.datasets.ImageFolder(\n",
    "    '~/Documents/research/imagenet/ILSVRC/Data/CLS-LOC/train/',\n",
    "    transform=transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.TenCrop(224),\n",
    "        transforms.Lambda(\n",
    "            lambda crops: torch.stack([\n",
    "                transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                ])(crop)\n",
    "                for crop in crops\n",
    "            ])\n",
    "        ),\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e444edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, data, batch_size=256, num_epochs=10):\n",
    "    data_loader = torch.utils.data.DataLoader2(\n",
    "        data,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=2,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    optimizer = optim.AdamW(model.parameters())\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    model.to(device)\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0.0\n",
    "        for inputs, labels in tqdm(data_loader):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs.to(device))\n",
    "            loss = criterion(outputs, labels.to(device))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        print(f'[epoch {epoch}]: loss: {epoch_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41ed728c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, data, batch_size=64):\n",
    "    data_loader = torch.utils.data.DataLoader2(\n",
    "        data,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        model.to(device)\n",
    "        correct = torch.tensor(0).to(device)\n",
    "        total = len(data_loader)\n",
    "        for inputs, labels in tqdm(data_loader):\n",
    "            bs, ncrops, c, h, w = inputs.shape\n",
    "            outputs = model(inputs.view(-1, c, h, w).to(device))\n",
    "            outputs = outputs.view(bs, ncrops, -1).mean(1).max(dim=1).indices.flatten()\n",
    "            labels = labels.view(-1, 1).flatten().to(device)\n",
    "            correct.add_((outputs == labels).sum())\n",
    "        print(correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7301cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9/20019 [01:01<37:46:56,  6.80s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m eval_model(resnet152, eval_data)\n",
      "Cell \u001b[0;32mIn[12], line 16\u001b[0m, in \u001b[0;36meval_model\u001b[0;34m(model, data, batch_size)\u001b[0m\n\u001b[1;32m     14\u001b[0m     outputs \u001b[39m=\u001b[39m model(inputs\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, c, h, w)\u001b[39m.\u001b[39mto(device))\n\u001b[1;32m     15\u001b[0m     outputs \u001b[39m=\u001b[39m outputs\u001b[39m.\u001b[39mview(bs, ncrops, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mmean(\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mmax(dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mindices\u001b[39m.\u001b[39mflatten()\n\u001b[0;32m---> 16\u001b[0m     labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39;49mview(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39;49mflatten()\u001b[39m.\u001b[39;49mto(device)\n\u001b[1;32m     17\u001b[0m     correct\u001b[39m.\u001b[39madd_((outputs \u001b[39m==\u001b[39m labels)\u001b[39m.\u001b[39msum())\n\u001b[1;32m     18\u001b[0m \u001b[39mprint\u001b[39m(correct \u001b[39m/\u001b[39m total)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "eval_model(resnet152, eval_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53a32b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5005 [00:00<?, ?it/s]/Users/marakim/opt/anaconda3/envs/network_inflation/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: dlopen(/Users/marakim/opt/anaconda3/envs/network_inflation/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.8.dylib\n",
      "  Referenced from: <BE0CCD9A-269A-30E2-A23C-DA45E89EBB1F> /Users/marakim/opt/anaconda3/envs/network_inflation/lib/python3.10/site-packages/torchvision/image.so\n",
      "  Reason: tried: '/Users/marakim/opt/anaconda3/envs/network_inflation/lib/python3.10/site-packages/torchvision/../../../libjpeg.8.dylib' (no such file), '/Users/marakim/opt/anaconda3/envs/network_inflation/lib/python3.10/site-packages/torchvision/../../../libjpeg.8.dylib' (no such file), '/Users/marakim/opt/anaconda3/envs/network_inflation/lib/python3.10/lib-dynload/../../libjpeg.8.dylib' (no such file), '/Users/marakim/opt/anaconda3/envs/network_inflation/bin/../lib/libjpeg.8.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS@rpath/libjpeg.8.dylib' (no such file), '/Users/marakim/opt/anaconda3/envs/network_inflation/lib/python3.10/site-packages/torchvision/../../../libjpeg.8.dylib' (no such file), '/Users/marakim/opt/anaconda3/envs/network_inflation/lib/python3.10/site-packages/torchvision/../../../libjpeg.8.dylib' (no such file), '/Users/marakim/opt/anaconda3/envs/network_inflation/lib/python3.10/lib-dynload/../../libjpeg.8.dylib' (no such file), '/Users/marakim/opt/anaconda3/envs/network_inflation/bin/../lib/libjpeg.8.dylib' (no such file), '/usr/local/lib/libjpeg.8.dylib' (no such file), '/usr/lib/libjpeg.8.dylib' (no such file, not in dyld cache)\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n",
      "/Users/marakim/opt/anaconda3/envs/network_inflation/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: dlopen(/Users/marakim/opt/anaconda3/envs/network_inflation/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.8.dylib\n",
      "  Referenced from: <BE0CCD9A-269A-30E2-A23C-DA45E89EBB1F> /Users/marakim/opt/anaconda3/envs/network_inflation/lib/python3.10/site-packages/torchvision/image.so\n",
      "  Reason: tried: '/Users/marakim/opt/anaconda3/envs/network_inflation/lib/python3.10/site-packages/torchvision/../../../libjpeg.8.dylib' (no such file), '/Users/marakim/opt/anaconda3/envs/network_inflation/lib/python3.10/site-packages/torchvision/../../../libjpeg.8.dylib' (no such file), '/Users/marakim/opt/anaconda3/envs/network_inflation/lib/python3.10/lib-dynload/../../libjpeg.8.dylib' (no such file), '/Users/marakim/opt/anaconda3/envs/network_inflation/bin/../lib/libjpeg.8.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS@rpath/libjpeg.8.dylib' (no such file), '/Users/marakim/opt/anaconda3/envs/network_inflation/lib/python3.10/site-packages/torchvision/../../../libjpeg.8.dylib' (no such file), '/Users/marakim/opt/anaconda3/envs/network_inflation/lib/python3.10/site-packages/torchvision/../../../libjpeg.8.dylib' (no such file), '/Users/marakim/opt/anaconda3/envs/network_inflation/lib/python3.10/lib-dynload/../../libjpeg.8.dylib' (no such file), '/Users/marakim/opt/anaconda3/envs/network_inflation/bin/../lib/libjpeg.8.dylib' (no such file), '/usr/local/lib/libjpeg.8.dylib' (no such file), '/usr/lib/libjpeg.8.dylib' (no such file, not in dyld cache)\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n",
      "  0%|          | 13/5005 [02:19<14:51:58, 10.72s/it]"
     ]
    }
   ],
   "source": [
    "train_model(resnet152, train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b785741c",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(map(\n",
    "    lambda x: x.eval(),\n",
    "    resnets\n",
    "))\n",
    "\"Eval mode\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8469a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = next(iter(training_data))\n",
    "input_tensor = preprocess(image['image'])\n",
    "input_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5458c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(resnet18, [1, *input_tensor.shape])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3393763d",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(map(\n",
    "    lambda x: x.conv1,\n",
    "    resnets\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bff988",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(weight0, weight1):\n",
    "    cos = nn.functional.cosine_similarity\n",
    "    return torch.stack(tuple(\n",
    "        cos(\n",
    "            weight0[idx].expand(weight1.shape),\n",
    "            weight1,\n",
    "        )\n",
    "        for idx in range(weight0.shape[0])\n",
    "    ))\n",
    "\n",
    "\n",
    "def histogram(input, bins=100, range=(0,1), width=1):\n",
    "    histogram = input.histogram(bins=bins,range=range)\n",
    "    plt.bar(\n",
    "        x=histogram.bin_edges[:-1].detach(),\n",
    "        height=histogram.hist.detach(),\n",
    "        width=width*(range[1]-range[0])/bins,\n",
    "        align='edge')\n",
    "\n",
    "def random_unit(shape):\n",
    "    return torch.normal(torch.zeros(shape), torch.ones(shape))\n",
    "\n",
    "def self_similarity(network0):\n",
    "    weight0 = network0.conv1.get_parameter('weight').flatten(start_dim=1)\n",
    "    measure = cosine_similarity(weight0, weight0).fill_diagonal_(0).abs().max(dim=1).values\n",
    "    histogram(measure)\n",
    "\n",
    "def similarity(network0, network1):\n",
    "    measure = cosine_similarity(\n",
    "        network0.conv1.get_parameter('weight').flatten(start_dim=1),\n",
    "        network1.conv1.get_parameter('weight').flatten(start_dim=1),\n",
    "    ).abs().max(dim=1).values\n",
    "    histogram(measure)\n",
    "\n",
    "def null_similarity(network0):\n",
    "    weight0 = network0.conv1.get_parameter('weight').flatten(start_dim=1)\n",
    "    measure = torch.stack([\n",
    "        cosine_similarity(\n",
    "            weight0,\n",
    "            random_unit(weight0.shape)\n",
    "        ).abs().max(dim=1).values\n",
    "        for _ in range(2048)\n",
    "    ])\n",
    "    histogram(measure, bins=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a02aef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "self_similarity(resnet50)\n",
    "self_similarity(resnet101)\n",
    "self_similarity(resnet152)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c650b382",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity(resnet50, resnet152)\n",
    "\n",
    "similarity(resnet101, resnet152)\n",
    "\n",
    "similarity(resnet152, resnet101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ec9e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_similarity(resnet152)\n",
    "\n",
    "[x for x,_ in resnet50.named_parameters()]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "network_inflation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "a85702dbffca433bbc1cdca1ec61af2a74010ab6cab1a97332d28220958107a8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
